{
	"properties": {},
	"description": "Welding audio detection trainer",
	"processes": {
		"python3operator2": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "DatasetImport",
				"x": 24,
				"y": 200,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "\nimport boto3\n\nimport fnmatch\nimport os\nimport os.path\nimport re\nimport time\nimport zipfile\nimport shutil\n    \nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\n\nretrain = True\nmodel_dir_name = \"/tmp/\"\nhome_dir = '/tmp/'   \n\ndef out_debug(message):\n    api.send(\"debug\", message)\n    \n    \ndef trigger_download():\n    dataset =  api.config.dataset\n    out_debug( \"Volume contents {}\".format ( str(get_files(model_dir_name, ['*.*'])) ) )\n    out_debug( \"Downloading training dataset {}\".format(dataset) )\n    \n    out_debug(\"Establishing connection to AWS S3 ...\")\n    conn = get_aws_connection()\n    out_debug(\"AWS connection: Done, starting download\")\n    \n    try:\n        download_data(conn, 'edgepoc', dataset, home_dir)\n    \n        out_debug( \"Volume contents {}\".format ( str(get_files(model_dir_name, ['*.*'])) ) )\n        api.send(\"debug\", \"Downloading complete, exploding data\")   \n    except Exception as e:\n        out_debug(\"Error downloading training data {}\".format(str(e)))\n        \n    zip_filename = dataset.split('/')[-1]\n   \n    try:\n        with zipfile.ZipFile(home_dir+zip_filename, 'r') as zip_ref:\n           zip_ref.extractall(home_dir)\n           \n        out_debug( \"Training data exploded\")\n        out_debug( \"Volume contents {}\".format ( str(get_files(model_dir_name, ['*.*'])) ) )\n        \n        api.send(\"output\", \"training_data_ready\")\n        \n    \n    except Exception as e:\n        api.send(\"debug\", str(e))\n        \n    out_debug(\"No training data found\")\n       \n   \ndef split_aut_files():\n\n    for fname in get_files(home_dir+'/input/good/'):\n        split_file(fname, home_dir+'split/good/')\n        api.send(\"debug\", \"Splitting /input/good/{}\".format(fname))\n  \n    api.send(\"debug\", \"test2\")   \n    for fname in get_files(home_dir+'/input/bad/'):\n        split_file(fname, home_dir+'split/bad/')\n        api.send(\"debug\", \"Splitting /input/good/{}\".format(fname))\n        \n    for fname in get_files(home_dir+'/input/ignore/'):\n        split_file(fname, home_dir+'split/ignore/')\n        api.send(\"debug\", \"Splitting /input/good/{}\".format(fname))\n        \n    \n\ndef status():\n    for fname in get_files(home_dir+'/input/good/'):\n        api.send(\"debug\", str(fname))\n        \n        \n\napi.add_timer(\"36000s\", trigger_download)\n\n\n##### reuslable modules\ndef get_files (d, includes = ['*.json', '*.h5', '*.mp3', '*.wav'] ):\n    excludes = ['/home/ram/doc'] # for dirs and files\n    # transform glob patterns to regular expressions\n    includes = r'|'.join([fnmatch.translate(x) for x in includes])\n    excludes = r'|'.join([fnmatch.translate(x) for x in excludes]) or r'$.'\n    files = []\n    for root, dirs, files in os.walk(d):\n        api.send (\"debug\", \"dir {} dir {} files {}\".format(d, dirs, files))\n        # exclude dirs\n        dirs[:] = [os.path.join(root, d) for d in dirs]\n        dirs[:] = [d for d in dirs if not re.match(excludes, d)]\n    \n        # exclude/include files\n        files = [os.path.join(root, f) for f in files]\n        files = [f for f in files if not re.match(excludes, f)]\n        files = [f for f in files if re.match(includes, f)]\n\n    return files\n        \n\n\ndef get_aws_connection():\n    boto3.setup_default_session(region_name='eu-central-1')\n    s3  = boto3.client(\n        's3',\n        # Hard coded strings as credentials, not recommended.\n        aws_access_key_id='<aws_key>',\n        aws_secret_access_key='<aws_secret>',\n        region_name = 'eu-central-1'\n    )  \n    return s3\n    \n\n\ndef download_data(s3_client, bucket, obj_name, ouput_dir):\n    s3_client.download_file(bucket, obj_name, ouput_dir+obj_name.split('/')[-1])\n\n    return True\n\n\n        \n###\n        ",
					"dataset": "data/train_demo2.zip"
				},
				"additionaloutports": [
					{
						"name": "output",
						"type": "string"
					},
					{
						"name": "debug",
						"type": "string"
					}
				]
			}
		},
		"python3operator4": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "Audio_Splitter",
				"x": 208.99999904632568,
				"y": 185.50000023841858,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "from pydub import AudioSegment\nfrom pydub.utils import make_chunks\nimport shutil, sys\nimport os, fnmatch, re\nimport time\n\nmodel_dir_name = \"/tmp/\"\nhome_dir = '/tmp/'   \n\ndef on_input(data):\n    out_debug(str(get_group_index()))\n    out_debug (\"Input ready, splitting audio \")\n\n    split_files('/tmp/train/', '/tmp/split/')\n    \n    api.send(\"output\", str(data))\n\napi.set_port_callback(\"input\", on_input)\n\n\ndef split_file (sound_file, output_dir):\n    if not os.path.exists(output_dir):\n        # creating diretory for split files if necessary\n        os.makedirs(output_dir)\n\n    if sound_file.endswith('.wav'):  \n        myaudio = AudioSegment.from_wav(sound_file)\n    else:\n        myaudio = AudioSegment.from_mp3(sound_file)\n        \n    chunks = make_chunks(myaudio, 1000) \n    fname = sound_file.split('/')[-1]\n    for i, chunk in enumerate(chunks):\n        chunk.export(\"{}{}{}.wav\".format(output_dir,fname, i))\n        out_debug (\"{}{}{}.wav\".format(output_dir,fname, i))\n\n        \ndef split_files(src, dst):\n    start = time.time()\n    count_f, count_s = 0, 0\n    try:\n        dirs = list(os.walk(src))[0][1]\n        \n        for d in dirs:\n            out_debug ('Reading directory {}'.format(d))\n            out_debug ('Recreating output directory {}'.format((dst+d)) )\n            rmdir(dst+d)\n            mkdir(dst+d)\n            for sound_file in get_files(src+d):\n                count_f += 1\n                out_debug ('Splitting dir {}, file {}'.format(dst+d+'/', sound_file))\n                split_file(sound_file, dst+d+'/')\n    except Exception as e:\n        out_debug(\"No files to process: {}\".format(str(e)))\n    end = time.time()\n    out_debug (\"{} files processed in {} seconds\".format(count_f, end-start))\n  \ndef get_files (d, includes = ['*.wav', '*.mp3'] ):\n    excludes = ['/home/ram/doc'] # for dirs and files\n    \n    # transform glob patterns to regular expressions\n    includes = r'|'.join([fnmatch.translate(x) for x in includes])\n    excludes = r'|'.join([fnmatch.translate(x) for x in excludes]) or r'$.'\n    \n    files = []\n    for root, dirs, files in os.walk(d):\n        dirs[:] = [os.path.join(root, d) for d in dirs]\n        dirs[:] = [d for d in dirs if not re.match(excludes, d)]\n    \n        # exclude/include files\n        files = [os.path.join(root, f) for f in files]\n        files = [f for f in files if not re.match(excludes, f)]\n        files = [f for f in files if re.match(includes, f)]\n    \n    return files\n    \ndef rmdir(dir_path):\n    try:\n        shutil.rmtree(dir_path)\n    except:\n        print('Error deleteing directory {}:  {}'.format(dir_path, sys.exc_info()[0]))\n\n\ndef mkdir(dir_path):\n    try:\n        print(\"create directory {}\".format(dir_path))\n        os.makedirs(dir_path)\n    except FileExistsError:\n        print('Error creating directory {}: {}'.format(dir_path,sys.exc_info()[0]))\n\ndef get_group_index():\n    ret = 0\n    try:\n        ret = int(api.group_id.split('-')[1])\n        out_debug(str(api))\n    except Exception as e:\n        out_debug(\"get_group_index: {}. Defaulting to 0\".format(str(e)))\n    return ret\n    \n\n            \ndef out_debug(message):\n    api.send(\"debug\", message)\n              \n            "
				},
				"additionalinports": [
					{
						"name": "input",
						"type": "string"
					}
				],
				"additionaloutports": [
					{
						"name": "output",
						"type": "string"
					},
					{
						"name": "debug",
						"type": "string"
					}
				]
			}
		},
		"python3operator1": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "Train",
				"x": 393.99999809265137,
				"y": 177.00000023841858,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"script": "from __future__ import print_function\nimport tensorflow as tf\nimport numpy as np\nimport keras\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense, LSTM, Activation, Dense, Dropout, Input, Embedding, TimeDistributed, Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.preprocessing import image\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM\nimport matplotlib.pyplot as plt\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom sklearn.utils import shuffle\nfrom keras import regularizers\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import SGD\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\nfrom keras import regularizers\nfrom keras.callbacks import LearningRateScheduler\nfrom keras import backend as K\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import roc_auc_score\n\nimport boto3\n\nimport fnmatch, os, os.path, re, time\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks\n\nimport librosa\nimport librosa.display\nfrom sklearn.metrics import roc_auc_score\n\nretrain = False\n\ndata_dir = '/tmp/'\nmodel_dir_name = data_dir + 'model/'\nhome_dir = data_dir \n\ndef on_input(data):\n    global retrain\n    ## train data available\n    retrain = True\n    api.send(\"output\", str(data))\n\napi.set_port_callback(\"input\", on_input)\n    \n    \ndef run_training():\n    global retrain\n    if retrain:\n        out_debug( \"Triggering fresh training\")\n        model = train2()\n        api.send(\"model\", model)\n        retrain = False\n    else:\n        api.send(\"output\", \"Model already trained\")\n\napi.add_timer(\"2s\", run_training)        \n\n\n\ndef train():\n    model = RNN()\n    \n    ## run training\n    history = model.fit(x_train,\n            y_train,\n            epochs=EPOCHES,\n            validation_data=(x_test, y_test))\n    \n    # save model\n    model_digit_json = model.to_json()\n    with open(model_dir_name+\"rnn_image.json\", \"w\") as json_file:\n        json_file.write(model_digit_json)\n    # serialize weights to HDF5\n    model.save_weights(model_dir_name+'rnn_image.h5')\n    \n    print(\"Saved model to disk\")\n    \n\ndef get_files (d):\n    includes = ['*.json', '*.h5', '*.mp3', '*.wav'] # for files only\n    excludes = ['/home/ram/doc'] # for dirs and files\n    \n    # transform glob patterns to regular expressions\n    includes = r'|'.join([fnmatch.translate(x) for x in includes])\n    excludes = r'|'.join([fnmatch.translate(x) for x in excludes]) or r'$.'\n    \n    files = []\n    for root, dirs, files in os.walk(d):\n        out_debug (\"dir {} dir {} files {}\".format(d, dirs, files))\n        # exclude dirs\n        dirs[:] = [os.path.join(root, d) for d in dirs]\n        dirs[:] = [d for d in dirs if not re.match(excludes, d)]\n    \n        # exclude/include files\n        files = [os.path.join(root, f) for f in files]\n        files = [f for f in files if not re.match(excludes, f)]\n        files = [f for f in files if re.match(includes, f)]\n   \n    return files\n        \n\n## model\n\ndef RNN(): \n    model = Sequential()\n    model.add(LSTM(128, input_shape=(x_train.shape[1:]), activation='relu', return_sequences=True))\n    model.add(Dropout(0.2))\n\n    model.add(LSTM(128, activation='relu'))\n    model.add(Dropout(0.1))\n\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.2))\n\n    model.add(Dense(10, activation='softmax'))\n\n    model.compile(\n        loss='sparse_categorical_crossentropy',\n        optimizer='adam',\n        metrics=['accuracy'],\n    )\n    return model\n\n        \n##### reuslable modules\ndef get_aws_connection():\n    boto3.setup_default_session(region_name='eu-central-1')\n    s3  = boto3.client(\n        's3',\n        # Hard coded strings as credentials, not recommended.\n        aws_access_key_id='<aws_key>',\n        aws_secret_access_key='<aws_secret>',\n        region_name = 'eu-central-1'\n    )  \n    return s3\n    \n\n###  extract features\ndef extract_features(input_data_dir):\n    x = []\n    y = []\n    \n    classes = [c for c in os.listdir(input_data_dir) if c!='.DS_Store']\n    out_debug( \"Audio classes detected: {}\".format(str(classes)) )\n    \n    for c in classes:\n\n            tmpx = []\n            tmpy = []\n            out_debug('Processing class {}'.format (c))\n\n            for file in [f for f in os.listdir(input_data_dir + c) if f!='.DS_Store']:\n                f = input_data_dir + c +'/' + file\n                out_debug(\"Generating features for file {}\".format(f))\n                try:\n                    wave,sr = librosa.load(f, mono=True)\n                    mfcc = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=20)\n                    mfcc_pad = np.zeros((20, 44))\n                    mfcc_pad[:mfcc.shape[0], :mfcc.shape[1]] = mfcc[:20, :44]\n                \n                    if mfcc_pad.shape == (20, 44):\n                        x.append(mfcc_pad)\n                        tmpx.append(mfcc_pad)\n                        y.append(classes.index(c))\n                        tmpy.append(classes.index(c))\n                except Exception as e:\n                    out_debug(\"Error processing audio file {}\".format(str(e)) )\n\n    print('complete')\n    return np.array(x), np.array(y)\n  \n\nclass Monitor_callback(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        return\n \n    def on_train_end(self, logs={}):\n        return\n \n    def on_epoch_begin(self, epoch, logs={}):\n        return\n \n    def on_epoch_end(self, epoch, logs={}):\n        #out_debug(\"Epoc {}, Loss: {}\".format( epoch, logs.get('loss') ) )\n        #y_pred = self.model.predict(self.model.validation_data[0])\n        #out_debug(\"Prediction {} for {}\".format(y_pred, self.model.validation_data[0]) )\n        #out_debug(\"Roc score {}\".format( roc_auc_score(self.model.validation_data[1], y_pred ) ) )\n        out_debug(\"Epoch: {}, {} \".format(epoch, str(logs)))\n \n    def on_batch_begin(self, batch, logs={}):\n        return\n \n    def on_batch_end(self, batch, logs={}):\n        #self.losses.append(logs.get('loss'))\n        return    \n    \ndef train2():\n    out_debug(\"Extracting audio MFCC vectors ..\")\n    x, y = extract_features(data_dir+'split/')\n    out_debug(\"Features extracted, ...shuffling ..\")\n    x, y = shuffle(x, y)\n    x_train = x.reshape(-1, 20, 44, 1)\n    y_train = y.reshape(-1)\n    \n    #Converting categorical classes to wide format classes [\n    y_train = to_categorical(y, num_classes = 2)\n    \n\n    weight_decay = 1e-4\n    model = Sequential()\n    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n    \n    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    \n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.2))\n     \n    \n    model.add(Flatten())\n    #model.add(Dense(5, activation='softmax'))\n    model.add(Dense(2, activation='softmax')) # num classes\n    opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n    model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n    \n    out_debug(\"Fitting model ..\")\n    model.fit(x=x_train,\n          y=y_train, epochs=100, validation_split=0.1, callbacks=[Monitor_callback()])\n    \n    out_debug(\"Fitting model done, model ready for upload\")\n    #upload_models(model, 'audio_detect')\n    \n    return model\n\n\ndef out_debug(message):\n    api.send(\"debug\", message)\n    \n    \n"
				},
				"additionalinports": [
					{
						"name": "input",
						"type": "string"
					}
				],
				"additionaloutports": [
					{
						"name": "output",
						"type": "string"
					},
					{
						"name": "debug",
						"type": "string"
					},
					{
						"name": "model",
						"type": "python36"
					}
				]
			}
		},
		"python3operator3": {
			"component": "com.sap.system.python3Operator",
			"metadata": {
				"label": "ModelExport",
				"x": 594.999997138977,
				"y": 191.5,
				"height": 80,
				"width": 120,
				"extensible": true,
				"config": {
					"target": "aws",
					"script": "\nimport boto3\n\nimport fnmatch, os, os.path, re, time\n\ndata_dir = '/tmp/'\nmodel_dir_name = data_dir + 'model/'\n\n\ndef on_input(data):\n    api.send(\"output\", str(data))\n\napi.set_port_callback(\"input\", on_input)\n\n\ndef on_model_in(model):\n    out_debug(\"Preparing model for uploading\")\n    upload_models(model, api.config.model)\n    out_debug(\"Uploading model done\")\n   \n\napi.set_port_callback(\"model\", on_model_in)\n\ndef upload_models(model, name):     \n    out_debug(\"Received model {} for uploading\".format(str(model)))\n    if not os.path.exists(model_dir_name):\n        out_debug ('creating directory {}'.format(model_dir_name))\n        os.makedirs(model_dir_name)\n    else:\n        out_debug('Using directory {} for staging model artifqcts'.format(model_dir_name))\n\n    model_digit_json = model.to_json()\n\n    with open(model_dir_name+\"{}.json\".format(name), \"w\") as json_file:\n        json_file.write(model_digit_json)\n    # serialize weights to HDF5\n    model.save_weights(model_dir_name+'{}.h5'.format(name))\n    out_debug(\"writing weights to \"+model_dir_name+'{}.h5'.format(name))\n    \n    local_dir = model_dir_name\n    \n    out_debug(\"Model serialized and saved, starting upload\")\n    ### upload to s3\n    boto3.setup_default_session(region_name='eu-central-1')\n    s3  = boto3.client(\n        's3',\n        # Hard coded strings as credentials, not recommended.\n        aws_access_key_id='<aws_key>',\n        aws_secret_access_key='<aws_secret>',\n        region_name = 'eu-central-1'\n    )  \n    \n    bucket_name = 'edgepoc'\n    files = get_files(local_dir, ['*.json', '*.h5'])\n    out_debug(str(files))\n    \n    for f in files:\n        with open(f, 'rb') as data:\n            s3.upload_fileobj(data, bucket_name, 'model/'+f.split('/')[-1])\n\n\ndef get_files (d, includes = ['*.wav', '*.mp3'] ):\n    excludes = ['/home/ram/doc'] # for dirs and files\n    \n    # transform glob patterns to regular expressions\n    includes = r'|'.join([fnmatch.translate(x) for x in includes])\n    excludes = r'|'.join([fnmatch.translate(x) for x in excludes]) or r'$.'\n    \n    files = []\n    for root, dirs, files in os.walk(d):\n        dirs[:] = [os.path.join(root, d) for d in dirs]\n        dirs[:] = [d for d in dirs if not re.match(excludes, d)]\n    \n        # exclude/include files\n        files = [os.path.join(root, f) for f in files]\n        files = [f for f in files if not re.match(excludes, f)]\n        files = [f for f in files if re.match(includes, f)]\n    \n    return files\n    \n    \ndef out_debug(message):\n    api.send(\"debug\", message)\n    \n    \n",
					"model": "audio_detectx_demo10"
				},
				"additionalinports": [
					{
						"name": "input",
						"type": "string"
					},
					{
						"name": "model",
						"type": "python36"
					}
				],
				"additionaloutports": [
					{
						"name": "output",
						"type": "string"
					},
					{
						"name": "debug",
						"type": "string"
					}
				]
			}
		},
		"terminal2": {
			"component": "com.sap.util.terminal",
			"metadata": {
				"label": "Terminal",
				"x": 887.9999952316284,
				"y": 12,
				"height": 80,
				"width": 120,
				"ui": "dynpath",
				"config": {}
			}
		},
		"terminal3": {
			"component": "com.sap.util.terminal",
			"metadata": {
				"label": "Terminal",
				"x": 887.9999952316284,
				"y": 372,
				"height": 80,
				"width": 120,
				"ui": "dynpath",
				"config": {}
			}
		},
		"terminal1": {
			"component": "com.sap.util.terminal",
			"metadata": {
				"label": "Terminal",
				"x": 887.9999952316284,
				"y": 132,
				"height": 80,
				"width": 120,
				"ui": "dynpath",
				"config": {}
			}
		},
		"terminal4": {
			"component": "com.sap.util.terminal",
			"metadata": {
				"label": "Terminal",
				"x": 887.9999952316284,
				"y": 252,
				"height": 80,
				"width": 120,
				"ui": "dynpath",
				"config": {}
			}
		}
	},
	"groups": [
		{
			"name": "group1",
			"nodes": [
				"python3operator2",
				"python3operator4",
				"python3operator1",
				"python3operator3"
			],
			"metadata": {
				"description": "Group"
			},
			"tags": {
				"edgeml2": "",
				"python36": "",
				"tornado": "5.0.2"
			},
			"multiplicity": 1
		}
	],
	"connections": [
		{
			"metadata": {
				"points": "517.9999980926514,217.00000023841858 545.9999976158142,217.00000023841858 545.9999976158142,162.50000047683716 746.9999966621399,162.50000047683716 746.9999966621399,223.5 838.9999957084656,223.5 838.9999957084656,52 882.9999952316284,52"
			},
			"src": {
				"port": "debug",
				"process": "python3operator1"
			},
			"tgt": {
				"port": "in1",
				"process": "terminal2"
			}
		},
		{
			"metadata": {
				"points": "148,249 175.99999952316284,249 175.99999952316284,293.4999997615814 360.9999985694885,293.4999997615814 360.9999985694885,301.9999997615814 545.9999976158142,301.9999997615814 545.9999976158142,316.49999952316284 762.9999966621399,316.49999952316284 762.9999966621399,256.5 838.9999957084656,256.5 838.9999957084656,412 882.9999952316284,412"
			},
			"src": {
				"port": "debug",
				"process": "python3operator2"
			},
			"tgt": {
				"port": "in1",
				"process": "terminal3"
			}
		},
		{
			"metadata": {
				"points": "517.9999980926514,199.00000023841858 561.9999976158142,199.00000023841858 561.9999976158142,222.5 589.999997138977,222.5"
			},
			"src": {
				"port": "output",
				"process": "python3operator1"
			},
			"tgt": {
				"port": "input",
				"process": "python3operator3"
			}
		},
		{
			"metadata": {
				"points": "332.9999990463257,216.50000023841858 360.9999985694885,216.50000023841858 360.9999985694885,217.00000023841858 388.99999809265137,217.00000023841858"
			},
			"src": {
				"port": "output",
				"process": "python3operator4"
			},
			"tgt": {
				"port": "input",
				"process": "python3operator1"
			}
		},
		{
			"metadata": {
				"points": "332.9999990463257,234.50000023841858 360.9999985694885,234.50000023841858 360.9999985694885,284.9999997615814 561.9999976158142,284.9999997615814 561.9999976158142,299.49999952316284 746.9999966621399,299.49999952316284 746.9999966621399,245.5 854.9999957084656,245.5 854.9999957084656,292 882.9999952316284,292"
			},
			"src": {
				"port": "debug",
				"process": "python3operator4"
			},
			"tgt": {
				"port": "in1",
				"process": "terminal4"
			}
		},
		{
			"metadata": {
				"points": "517.9999980926514,235.00000023841858 545.9999976158142,235.00000023841858 545.9999976158142,240.5 589.999997138977,240.5"
			},
			"src": {
				"port": "model",
				"process": "python3operator1"
			},
			"tgt": {
				"port": "model",
				"process": "python3operator3"
			}
		},
		{
			"metadata": {
				"points": "718.999997138977,240.5 746.9999966621399,240.5 746.9999966621399,234.5 854.9999957084656,234.5 854.9999957084656,172 882.9999952316284,172"
			},
			"src": {
				"port": "debug",
				"process": "python3operator3"
			},
			"tgt": {
				"port": "in1",
				"process": "terminal1"
			}
		},
		{
			"metadata": {
				"points": "148,231 175.99999952316284,231 175.99999952316284,225.50000023841858 203.99999904632568,225.50000023841858"
			},
			"src": {
				"port": "output",
				"process": "python3operator2"
			},
			"tgt": {
				"port": "input",
				"process": "python3operator4"
			}
		}
	],
	"inports": {},
	"outports": {}
}